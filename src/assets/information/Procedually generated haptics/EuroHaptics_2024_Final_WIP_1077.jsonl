{"doc_id": "EuroHaptics_2024_Final_WIP_1077.pdf", "page": 1, "text": "Resonant Relaxation: Affective State Change via\nProcedurally Generated Haptics\nVincent Göke1,2[0009−0002−7682−8296], Jose Maria Santiago III1,2[0000−0002−4730−7865],\nMoritz Sendner1,2[0009−0003−0453−4587], and Daniel Shor3[0000−0003−3545−4961]\n1 Fachhochschule Salzburg GmbH, Urstein Süd 1, A-5412 Puch/Salzburg, Austria\nvgoeke.hcie-m2022@fh-salzburg.ac.at\n2 Paris-Lodron-Universität Salzburg, Jakob-Haringer-Straße 8 / Techno 5, 5020 Salzburg,\nAustria\nvincent.goeke@stud.plus.ac.at\n3 Innovobot Labs\ndshor@innovobot.com\nAbstract. The ongoing shift towards digital sedentary lifestyles has increased\nstress in daily life and calls for innovative approaches to improve mental and\nphysical health. This project explores the capabilities of AI-generated audio for\naffective haptic feedback to create experiences that induce relaxation and enhance\nemotional well-being and productivity. We designed a web application that al-\nlows haptic designers to create customized haptic patterns for respiration-based\nrelaxation practices. Our system offers customizable parameters and leverages AI-\ndriven audio-haptic composition to tailor relaxation experiences to individual user\nneeds. Initial findings suggest that generative AI supports designers in creating\npersonalized audio-haptic experiences, potentially reducing stress and improving\nrelaxation. This lays the groundwork for future exploration into broader emotional\nstate management.\nKeywords: Affective Haptics · Generative AI · Audio-Haptic Feedback · Person-\nalized Relaxation · Emotional Well-being\n1\nIntroduction\nIn recent years, the shift towards sedentary lifestyles due to ongoing digitalization and\nglobalization has highlighted the need for innovative approaches to maintaining mental\nand physical health. Traditional relaxation methods are often limited by modern living\nconditions, leading to the need for seamless solutions. Recent work has shown the poten-\ntial of haptics to produce affective shifts in users [3]. Other work has shown the ability of\nAI to produce music to foster mindfulness, specifically with relaxation [4], potentially\nimproving emotional well-being and productivity. In this paper, we explore the research\nquestion: \"How could generative AI support designers in creating relaxation-inducing\nhaptic experiences to enhance emotional well-being during sedentary activities?\" We\nbuild on previous work using personalized audio to reduce breathing rates and induce\nrelaxation [1, 2], and apply it within a haptic framework. Initial results highlight the\nchallenge posed by the highly contextual nature of haptic stimulation — affected by"}
{"doc_id": "EuroHaptics_2024_Final_WIP_1077.pdf", "page": 2, "text": "2\nGöke et al.\nfactors like baseline emotional state and environmental conditions — showing that in-\ntelligent and highly customizable solutions are needed to meet individual relaxation\nneeds effectively.\n2\nMethodology\nOur primary goal was to enhance users’ emotional well-being during concentrated\nproductivity or relaxation sessions by providing personalized audio-based haptic expe-\nriences that could promote relaxation and potentially facilitate a flow state. We focused\non creating a baseline state for relaxation, upon which we could then create follow-up\nshifts in the emotional state. To achieve this, we developed a React-based web application\ncapable of generating customized haptic patterns to induce relaxation. Using a ChatGPT\nAPI call, we generated initial MIDI compositions via a series of prompts. These MIDI\ncompositions were converted into waveforms using a browser-based synthesizer, Tone.js,\nand played through various voice coil actuators as wristband or neckband wearables. The\nhaptic output consisted of two sub-patterns: Firstly, an amplitude-modulated sine tone,\nwhich started at a frequency slightly higher than normal breathing and slowed down\naccording to user-defined parameters to induce slower breathing; secondly, AI-generated\nMIDI \"Sparkles\", aligning with the music theory of the baseline note frequency, ensured\nthe haptic experience remained engaging and novel. The web application combined the\ntwo in real time to create therapeutic soundscapes for haptic relaxation. We conducted\nan initial user test with three participants, each with a different sedentary workload, to\ncollect qualitative feedback for our development process. Participants reported increased\nfeelings of calm after using the system and preferred a variety of sparkles along with\na relaxing baseline over a simple haptic baseline output. However, the user testing was\nlimited and more extensive testing is planned for future iterations.\nFig. 1. Visualization of different types of musical note structures, generated using GPT-4 to add\nMIDI ’sparkles’ on top of the baseline frequency."}
{"doc_id": "EuroHaptics_2024_Final_WIP_1077.pdf", "page": 3, "text": "Resonant Relaxation: Affective State Change via Procedurally Generated Haptics\n3\n3\nConclusion and Future Work\nWe developed a web application that enables haptic designers to procedurally generate\nfine-tuned haptic patterns4. It successfully met its primary objective by allowing de-\nsigners to innovate and experiment with personalized relaxation experiences. However,\nthere are areas for improvement, such as the need for more rigorous user testing. Future\nwork will focus on expanding the prototype’s capabilities based on initial findings. We\nwill implement a more structured and extensive user testing phase to gather quantitative\ndata on the system’s performance and user satisfaction. Long-term studies are needed\nto assess the effects of regular use on emotional well-being and productivity. Also,\nthe exploration of different embodiments and integration methods for haptic actuators\ncould refine the comfort and usability of the system. Additionally, we aim to include\nsophisticated features such as Cycling ’74’s RNBO patches5, which facilitate adjustable\nand deployable virtual instruments for audio-haptic playback. Utilizing technologies like\nlocal Large Language Models (LLMs) for generating procedurally-generated haptics or\ncreating biofeedback loops can provide more effective, personalized experiences. These\nadvancements could revolutionize interaction with affective haptic technology, making\nthese experiences more immersive and tailored to individual needs. We invite haptic de-\nsigners and researchers to build on this foundation and explore its potential to transform\naffective haptic user experiences across various domains.\nAcknowledgments. We would like to express our appreciation to our academic supervisors\nBernhard Maurer and Alexander Metscherjakov along with the Innovobot Labs team, particularly\nDaniel Shor, for their supportive roles in guiding us through this industry project.\nDisclosure of Interests. The authors have no competing interests to declare that are relevant to\nthe content of this WIP paper.\nReferences\n1. Bumatay, A., Seo, J.: Investigating the Role of Biofeedback and Haptic Stimulation in Mobile\nPaced Breathing Tools. pp. 287–303 (May 2017). https://doi.org/10.1007/978-3-319-58628-\n1_23\n2. Leslie,\nG.,\nGhandeharioun,\nA.,\nZhou,\nD.,\nPicard,\nR.W.:\nEngineering\nMusic\nto\nSlow Breathing and Invite Relaxed Physiology. In: 2019 8th International Confer-\nence on Affective Computing and Intelligent Interaction (ACII). pp. 1–7 (Sep 2019).\nhttps://doi.org/10.1109/ACII.2019.8925531,\nhttps://ieeexplore.ieee.org/document/8925531,\niSSN: 2156-8111\n3. MacLean, K.E.: Designing affective haptic experience for wellness and social communi-\ncation: where designers need affective neuroscience and psychology. Current Opinion in\nBehavioral Sciences 45, 101113 (Jun 2022). https://doi.org/10.1016/j.cobeha.2022.101113,\nhttps://www.sciencedirect.com/science/article/pii/S2352154622000195\n4. Williams, D., Hodge, V.J., Gega, L., Murphy, D., Cowling, P.I., Drachen, A.: AI and Automatic\nMusic Generation for Mindfulness. In: 2019 AES International Conference on Immersive and\nInteractive Audio: Creating the Next Dimension of Sound Experience. York, GBR (Mar 2019),\nhttps://eprints.whiterose.ac.uk/141387/, num Pages: 10\n4 Project Github: https://github.com/NesR0M/Resonant-Relaxation-Project/tree/main\n5 RNBO: https://cycling74.com/products/rnbo"}
